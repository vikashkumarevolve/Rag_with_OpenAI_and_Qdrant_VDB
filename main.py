# main.py
import streamlit as st
from app.ui import pdf_uploader
from app.pdf_utils import extract_text_from_pdf
from app.vectorstore_utils import create_qdrant_index, retrieve_relevant_docs
from app.chat_utils import get_chat_model, ask_chat_model
from app.config import OPENAI_API_KEY
from langchain.text_splitter import RecursiveCharacterTextSplitter
import time

st.set_page_config(
    page_title="MediChat Pro - Medical Document Assistant",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }
    .chat-message.user {
        background-color: #2b313e;
        color: white;
    }
    .chat-message.assistant {
        background-color: #f0f2f6;
        color: black;
    }
    .chat-message .timestamp {
        font-size: 0.8rem;
        opacity: 0.7;
        margin-top: 0.5rem;
    }
    .stButton > button {
        background-color: #ff4b4b;
        color: white;
        border-radius: 0.5rem;
        border: none;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
    .stButton > button:hover {
        background-color: #ff3333;
    }
    .upload-section {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "chat_model" not in st.session_state:
    st.session_state.chat_model = None

st.markdown("""
<div style="text-align: center; padding: 2rem 0;">
    <h1 style="color: #ff4b4b; font-size: 3rem; margin-bottom: 0.5rem;">üè• MediChat Pro</h1>
    <p style="font-size: 1.2rem; color: #666; margin-bottom: 2rem;">Your Intelligent Medical Document Assistant</p>
</div>
""", unsafe_allow_html=True)

# Sidebar for document upload
with st.sidebar:
    st.markdown("### üìÅ Document Upload")
    st.markdown("Upload your medical documents to start chatting!")
    
    uploaded_files = pdf_uploader()
    
    if uploaded_files:
        st.success(f"üìÑ {len(uploaded_files)} document(s) uploaded")
        
        if st.button("üöÄ Process Documents", type="primary"):
            with st.spinner("Processing your medical documents..."):
                # Extract text
                all_texts = [extract_text_from_pdf(file) for file in uploaded_files]
                
                # Split text into chunks
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000,
                    chunk_overlap=200,
                    length_function=len,
                )
                chunks = []
                for text in all_texts:
                    chunks.extend(text_splitter.split_text(text))
                
                # Create Qdrant index
                vectorstore = create_qdrant_index(chunks)
                st.session_state.vectorstore = vectorstore
                
                # Init chat model
                chat_model = get_chat_model(OPENAI_API_KEY)
                st.session_state.chat_model = chat_model
                
                st.success("‚úÖ Documents processed successfully!")
                st.balloons()

# Chat interface
st.markdown("### üí¨ Chat with Your Medical Documents")

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        st.caption(message["timestamp"])

# Handle new user input
if prompt := st.chat_input("Ask about your medical documents..."):
    timestamp = time.strftime("%H:%M")
    st.session_state.messages.append({
        "role": "user", "content": prompt, "timestamp": timestamp
    })
    
    with st.chat_message("user"):
        st.markdown(prompt)
        st.caption(timestamp)
    
    if st.session_state.vectorstore and st.session_state.chat_model:
        with st.chat_message("assistant"):
            with st.spinner("üîç Searching documents..."):
                relevant_docs = retrieve_relevant_docs(st.session_state.vectorstore, prompt)
                context = "\n\n".join([doc.page_content for doc in relevant_docs])
                
                system_prompt = f"""You are MediChat Pro, an intelligent medical document assistant. 
                Based on the following medical documents, provide accurate and helpful answers. 
                If the information is not in the documents, clearly state that.

                Medical Documents:
                {context}

                User Question: {prompt}

                Answer:"""
                
                response = ask_chat_model(st.session_state.chat_model, system_prompt)
            
            st.markdown(response)
            st.caption(timestamp)
            st.session_state.messages.append({
                "role": "assistant", "content": response, "timestamp": timestamp
            })
    else:
        with st.chat_message("assistant"):
            st.error("‚ö†Ô∏è Please upload and process documents first!")
            st.caption(timestamp)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; font-size: 0.9rem;">
    <p>ü§ñ Powered by OpenAI & Qdrant | üè• Medical Document Intelligence</p>
</div>
""", unsafe_allow_html=True)
